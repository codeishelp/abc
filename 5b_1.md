# Explicación del Cuaderno: Aprendizaje por Transferencia - Puerta Presidencial para Perros

Este cuaderno se centra en la técnica de aprendizaje por transferencia (*transfer learning*). Esta técnica permite tomar un modelo preentrenado en un gran conjunto de datos y adaptarlo para una nueva tarea, especialmente útil cuando se dispone de un conjunto de datos pequeño para la nueva tarea.

## 1. Introducción al Aprendizaje por Transferencia

*   **Celda de Markdown (Introducción):**
    *   Explica que el aprendizaje por transferencia es útil cuando no se tiene un modelo preentrenado exacto para la tarea deseada o no se dispone de un dataset grande.
    *   Compara el aprendizaje por transferencia con un artista que aplica habilidades de una disciplina (pintura) a otra (dibujo con carboncillo).
    *   Menciona que es especialmente poderoso para datasets pequeños, ayudando a evitar el sobreajuste y mejorar la generalización.

*   **Celda de Markdown (Objetivos):**
    *   Preparar un modelo preentrenado para el aprendizaje por transferencia.
    *   Realizar aprendizaje por transferencia con un dataset propio y pequeño sobre un modelo preentrenado.
    *   Ajustar finamente (*fine-tune*) el modelo para un rendimiento aún mejor.

*   **Celda de Código (Importaciones y Configuración del Dispositivo):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    import torch
    import torch.nn as nn
    from torch.optim import Adam
    from torch.utils.data import Dataset, DataLoader
    import torchvision.transforms.v2 as transforms
    import torchvision.io as tv_io

    import glob
    import json # No se usa directamente en este cuaderno, pero podría ser para etiquetas si no se infieren de carpetas
    from PIL import Image # Usado en MyDataset para abrir imágenes

    import utils # Probablemente contiene funciones auxiliares

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    torch.cuda.is_available()
    ```
    *   **Explicación:**
        *   `torch`, `torch.nn`, `torch.optim`, `torch.utils.data`: Módulos fundamentales de PyTorch.
        *   `torchvision.transforms.v2`, `torchvision.io`: Para transformaciones y lectura de imágenes.
        *   `glob`: Para encontrar archivos que coincidan con un patrón (útil para cargar imágenes de carpetas).
        *   `PIL.Image`: Para abrir y manipular imágenes.
        *   `utils`: Un archivo local que podría contener funciones de ayuda.
        *   `device`: Configura el dispositivo (GPU o CPU).
    *   **Posibles Modificaciones:**
        *   Si `utils.py` no se usa o tiene otro nombre, ajustar la importación.
        *   Añadir otras bibliotecas si son necesarias.

## 2. Una Puerta para Perros Personalizada

Se plantea el problema de crear una puerta que solo se abra para un perro específico (Bo), usando un dataset pequeño.

*   **Celda de Markdown (Descripción del Problema):**
    *   El objetivo es adaptar la puerta para perros del ejercicio anterior para que solo reconozca a "Bo", el perro presidencial de EE. UU.
    *   Se dispone de un dataset pequeño (30 fotos de Bo), lo que haría difícil entrenar un modelo desde cero debido al sobreajuste.
    *   El aprendizaje por transferencia es la solución propuesta.

*   **Celda de Markdown (Imagen de Bo):**
    *   Muestra una imagen de Bo.

### 2.1 Descargando el Modelo Preentrenado

Se carga un modelo VGG16 preentrenado en ImageNet.

*   **Celda de Markdown (Elección del Modelo):**
    *   Los modelos de ImageNet de `torchvision.models` son buenos para aprendizaje por transferencia en visión artificial.
    *   VGG16 es adecuado porque ImageNet incluye perros, por lo que ha aprendido características relevantes.

*   **Celda de Código (Carga de VGG16):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    from torchvision.models import vgg16
    from torchvision.models import VGG16_Weights

    # load the VGG16 network *pre-trained* on the ImageNet dataset
    weights = VGG16_Weights.DEFAULT
    vgg_model = vgg16(weights=weights)
    ```
    *   **Explicación:**
        *   Carga el modelo VGG16 con los pesos predeterminados entrenados en ImageNet.
    *   **Posibles Modificaciones:**
        *   Podrías elegir otro modelo preentrenado (ej. `resnet50`) y sus pesos correspondientes. Esto cambiaría la arquitectura y el número de características de salida de la base convolucional.

*   **Celda de Markdown (Adaptación de la Capa de Salida):**
    *   La última capa de ImageNet tiene 1000 unidades (para 1000 clases). Para este problema (Bo o no Bo), se necesitará una capa de salida diferente.

*   **Celda de Código (Mover Modelo al Dispositivo):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    vgg_model.to(device)
    ```
    *   **Explicación:** Mueve el modelo VGG16 al dispositivo configurado.

### 2.2 Congelando el Modelo Base

Las capas del modelo preentrenado se congelan para preservar su conocimiento.

*   **Celda de Markdown (Explicación de Congelar Capas):**
    *   Congelar las capas preentrenadas significa que sus pesos no se actualizarán durante la fase inicial del entrenamiento.
    *   Esto retiene el aprendizaje de ImageNet. Si no se congelaran, la información valiosa podría destruirse al entrenar con el nuevo dataset pequeño.
    *   Más tarde, se pueden descongelar para el "ajuste fino" (*fine-tuning*).
    *   Se hace estableciendo `requires_grad_` a `False`.

*   **Celda de Código (Congelar VGG16):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    vgg_model.requires_grad_(False)
    print("VGG16 Frozen")
    ```
    *   **Explicación:** Itera sobre todos los parámetros de `vgg_model` y establece `requires_grad` a `False`.
    *   **Posibles Modificaciones:** Si decides no congelar (no recomendado inicialmente), omite esto.

### 2.3 Añadiendo Nuevas Capas

Se añaden nuevas capas entrenables al final del modelo congelado.

*   **Celda de Markdown (Explicación de Nuevas Capas):**
    *   Estas nuevas capas tomarán las características extraídas por el modelo base y aprenderán a clasificarlas para la nueva tarea.
    *   Se añadirá una capa `Linear` que conecte las 1000 salidas de VGG16 (si se usa todo el clasificador de VGG16) a 1 neurona para la clasificación binaria (Bo o no Bo).

*   **Celda de Código (Definición del Nuevo Modelo):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    N_CLASSES = 1 # Salida binaria: Bo (0 o negativo) o no Bo (1 o positivo)

    my_model = nn.Sequential(
        vgg_model, # El modelo VGG16 completo (features + classifier original)
        nn.Linear(1000, N_CLASSES) # VGG16 termina con 1000 neuronas antes de la capa de salida de ImageNet
    )

    my_model.to(device)
    ```
    *   **Explicación:**
        *   `N_CLASSES = 1`: Para una clasificación binaria, una sola neurona de salida es suficiente. Su valor (antes de una sigmoide, si se usara explícitamente) puede interpretarse.
        *   `nn.Sequential(vgg_model, nn.Linear(1000, N_CLASSES))`:
            *   Se pasa `vgg_model` completo. La última capa lineal del clasificador de VGG16 (`vgg_model.classifier[6]`) tiene `out_features=1000`.
            *   Se añade una nueva capa `nn.Linear` que toma estas 1000 características y las mapea a `N_CLASSES` (1 en este caso).
    *   **Posibles Modificaciones:**
        *   Si quisieras usar solo las características convolucionales de VGG16 y construir un clasificador más complejo:
            ```python
            # Ejemplo alternativo:
            # N_CLASSES = 1
            # my_model = nn.Sequential(
            #     vgg_model.features, # Solo las capas convolucionales
            #     nn.Flatten(),
            #     nn.Linear(512 * 7 * 7, 256), # VGG16 features output es 512x7x7
            #     nn.ReLU(),
            #     nn.Dropout(0.5),
            #     nn.Linear(256, N_CLASSES)
            # )
            ```
            En este caso, `vgg_model.features` sería la base congelada. El `nn.Linear` tomaría como entrada el tamaño aplanado de la salida de `vgg_model.features`.
        *   El número de neuronas en la nueva capa lineal (1000 en este caso, porque se usa la salida del clasificador de VGG16) debe coincidir con la salida de la capa anterior.

*   **Celda de Markdown (Verificar Congelación):**
    *   Se puede verificar qué parámetros son entrenables.

*   **Celda de Código (Verificar `requires_grad`):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    for idx, param in enumerate(my_model.parameters()):
        print(idx, param.requires_grad)
    ```
    *   **Explicación:** Muestra `True` para los parámetros de la nueva capa `nn.Linear(1000, N_CLASSES)` y `False` para los parámetros de `vgg_model` (porque se congeló).

*   **Celda de Markdown (Descongelar Opcional):**
    *   Muestra cómo se descongelarían las capas si fuera necesario.

*   **Celda de Código (Ejemplo de Descongelar y Verificar):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    vgg_model.requires_grad_(True) # Descongela
    print("VGG16 Unfrozen")
    for idx, param in enumerate(my_model.parameters()):
        print(idx, param.requires_grad) # Ahora todos deberían ser True
    ```

*   **Celda de Markdown (Re-congelar para Entrenamiento Inicial):**
    *   Se vuelven a congelar las capas base para el entrenamiento inicial de las capas añadidas.

*   **Celda de Código (Re-congelar VGG16):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    vgg_model.requires_grad_(False)
    print("VGG16 Frozen")
    ```

### 2.4 Compilando el Modelo

Se define la función de pérdida y el optimizador.

*   **Celda de Markdown (Elección de Función de Pérdida):**
    *   Para clasificación binaria (Bo o no Bo), se usa entropía cruzada binaria (`BCELoss` o `BCEWithLogitsLoss`).
    *   `BCEWithLogitsLoss` es preferible porque es numéricamente más estable y toma *logits* (salidas crudas del modelo) directamente, sin necesidad de una capa Sigmoid explícita al final del modelo.
    *   `from_logits=True` (implícito en `BCEWithLogitsLoss`) informa a la función de pérdida que las salidas no están normalizadas (ej. por una sigmoide).

*   **Celda de Código (Pérdida y Optimizador):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    loss_function = nn.BCEWithLogitsLoss() # Para clasificación binaria, espera logits
    optimizer = Adam(my_model.parameters()) # Optimizará solo los parámetros con requires_grad=True
    my_model = my_model.to(device) # Asegura que todo el modelo (incluidas nuevas capas) esté en el device
    ```
    *   **Explicación:**
        *   `nn.BCEWithLogitsLoss()`: Combina una capa Sigmoid y `BCELoss` en una sola clase. Es más estable.
        *   `optimizer = Adam(my_model.parameters())`: El optimizador Adam. Solo actualizará los pesos de la capa `nn.Linear(1000, N_CLASSES)` porque las capas de `vgg_model` están congeladas.
    *   **Posibles Modificaciones:**
        *   Podrías probar otros optimizadores (`SGD`, etc.) o ajustar la tasa de aprendizaje de Adam (ej. `Adam(my_model.parameters(), lr=0.001)`).
        *   Si tuvieras más de dos clases, volverías a `nn.CrossEntropyLoss()`.

## 3. Aumento de Datos y Carga de Datos

Se preparan los datos, incluyendo el aumento de datos.

*   **Celda de Markdown (Transformaciones de Preprocesamiento):**
    *   Se obtienen las transformaciones de preprocesamiento de los pesos de VGG16.

*   **Celda de Código (Obtener `pre_trans`):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    pre_trans = weights.transforms()
    ```
    *   **Explicación:** Estas son las transformaciones estándar (redimensionar, normalizar, etc.) que VGG16 espera.

### 3.1 El Dataset

Se crea una clase `Dataset` personalizada para cargar imágenes de Bo y "no Bo".

*   **Celda de Markdown (Carga desde Archivos):**
    *   Las etiquetas se inferirán de la ruta del archivo (si está en la carpeta "bo" o "not_bo").

*   **Celda de Código (Clase `MyDataset`):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    DATA_LABELS = ["bo", "not_bo"] # "bo" será la clase 0, "not_bo" la clase 1
        
    class MyDataset(Dataset):
        def __init__(self, data_dir):
            self.imgs = []
            self.labels = []
            
            for l_idx, label_name in enumerate(DATA_LABELS): # l_idx será 0 para "bo", 1 para "not_bo"
                data_paths = glob.glob(data_dir + label_name + '/*.jpg', recursive=True)
                for path in data_paths:
                    img = Image.open(path) # Abre la imagen con PIL
                    # pre_trans espera una imagen PIL o un tensor. Si es PIL, la convierte a tensor.
                    self.imgs.append(pre_trans(img).to(device))
                    # Las etiquetas deben ser float para BCEWithLogitsLoss
                    self.labels.append(torch.tensor(l_idx).to(device).float())


        def __getitem__(self, idx):
            img = self.imgs[idx]
            label = self.labels[idx]
            return img, label # Devuelve la imagen preprocesada y su etiqueta

        def __len__(self):
            return len(self.imgs)
    ```
    *   **Explicación:**
        *   `DATA_LABELS`: Define las clases y su orden (importante para la asignación de etiquetas numéricas).
        *   `__init__`:
            *   Usa `glob` para encontrar todas las imágenes `.jpg` en las subcarpetas "bo" y "not_bo".
            *   Abre cada imagen con `PIL.Image.open()`.
            *   Aplica `pre_trans` (las transformaciones de VGG16) a cada imagen.
            *   Almacena las imágenes transformadas y sus etiquetas (0 o 1, convertidas a `float`). `BCEWithLogitsLoss` espera que las etiquetas objetivo sean de tipo float.
        *   Almacenar todas las imágenes preprocesadas en memoria (`self.imgs`) puede ser problemático para datasets muy grandes.
    *   **Posibles Modificaciones:**
        *   Si las imágenes tienen otro formato (ej. `.png`), cambia `/*.jpg`.
        *   Si el dataset es muy grande, carga y transforma imágenes bajo demanda en `__getitem__` en lugar de en `__init__`.
        *   El orden en `DATA_LABELS` determina qué clase es 0 y cuál es 1.

### 3.2 Los DataLoaders

Se crean `DataLoader`s para los conjuntos de entrenamiento y validación.

*   **Celda de Código (Creación de DataLoaders):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    n = 32 # Tamaño del lote

    train_path = "data/presidential_doggy_door/train/"
    train_data = MyDataset(train_path)
    train_loader = DataLoader(train_data, batch_size=n, shuffle=True) # Barajar para entrenamiento
    train_N = len(train_loader.dataset)

    valid_path = "data/presidential_doggy_door/valid/"
    valid_data = MyDataset(valid_path)
    valid_loader = DataLoader(valid_data, batch_size=n) # No es necesario barajar para validación
    valid_N = len(valid_loader.dataset)
    ```
    *   **Explicación:** Configuración estándar de `DataLoader`. `shuffle=True` para el entrenamiento es importante.
    *   **Posibles Modificaciones:** Ajustar `n` (tamaño del lote).

### 3.3 Aumento de Datos Adicional

Se definen transformaciones aleatorias para aumentar el conjunto de entrenamiento.

*   **Celda de Markdown (Uso de `ColorJitter`):**
    *   Como las imágenes son a color, se puede usar `ColorJitter` para variar brillo, contraste, saturación y tono.

*   **Celda de Código (Definición de `random_trans`):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    IMG_WIDTH, IMG_HEIGHT = (224, 224) # Tamaño esperado por VGG16

    random_trans = transforms.Compose([
        transforms.RandomRotation(25),
        transforms.RandomResizedCrop((IMG_WIDTH, IMG_HEIGHT), scale=(.8, 1), ratio=(1, 1), antialias=True), # antialias para v2
        transforms.RandomHorizontalFlip(),
        transforms.ColorJitter(brightness=.2, contrast=.2, saturation=.2, hue=.2)
    ])
    ```
    *   **Explicación:**
        *   `RandomRotation`: Rota la imagen aleatoriamente hasta 25 grados.
        *   `RandomResizedCrop`: Recorta una porción aleatoria y la redimensiona. `scale` controla el zoom, `ratio` la relación de aspecto.
        *   `RandomHorizontalFlip`: Voltea horizontalmente con probabilidad 0.5.
        *   `ColorJitter`: Ajusta aleatoriamente el brillo, contraste, saturación y tono.
    *   **Posibles Modificaciones:**
        *   Ajustar los parámetros de cada transformación (ej. grados de rotación, rangos de `scale` o `ColorJitter`).
        *   Añadir/quitar otras transformaciones de `torchvision.transforms.v2`.
        *   Estas transformaciones se aplicarán solo a los datos de entrenamiento.

## 4. El Bucle de Entrenamiento

Se definen las funciones de entrenamiento y validación.

*   **Celda de Markdown (Función `get_batch_accuracy`):**
    *   Para `BCEWithLogitsLoss`, la salida del modelo es un logit.
    *   Si el logit > 0, la predicción (después de una sigmoide implícita) es > 0.5 (clase 1).
    *   Si el logit < 0, la predicción es < 0.5 (clase 0).
    *   Por lo tanto, se compara la salida directamente con 0 para determinar la clase predicha.

*   **Celda de Código (Función `get_batch_accuracy`):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    def get_batch_accuracy(output, y, N_dataset_size): # N es el tamaño total del dataset para promediar la precisión
        zero_tensor = torch.tensor([0.0]).to(device) # Comparar con 0.0 para logits
        # output es (batch_size), y es (batch_size)
        pred = torch.gt(output, zero_tensor) # True si output > 0 (predice clase 1), False si output <= 0 (predice clase 0)
        # y contiene 0.0 o 1.0. Necesitamos que y sea booleano o igual tipo que pred para .eq()
        # Si DATA_LABELS = ["bo", "not_bo"], "bo" es 0, "not_bo" es 1.
        # Entonces, y.view_as(pred) debería funcionar si y es 0.0 o 1.0.
        # Si y es LongTensor, necesitaría y.bool().view_as(pred) o y.float().view_as(pred) si pred es float.
        # Dado que y se creó como float en MyDataset, y.view_as(pred) está bien si pred es float,
        # pero pred aquí es booleano.
        # Una forma más robusta:
        # y_bool = y.bool() # Convierte y (0.0 o 1.0) a booleano (False o True)
        # correct = pred.eq(y_bool).sum().item()
        # O, si se espera que pred sea 0 o 1:
        pred_labels = pred.float() # Convierte True/False a 1.0/0.0
        correct = pred_labels.eq(y.view_as(pred_labels)).sum().item()
        return correct / y.size(0) # Precisión del lote actual, no sobre N_dataset_size
                                   # Se sumará y promediará fuera.
    ```
    *   **Explicación (Corregida/Mejorada):**
        *   `zero_tensor = torch.tensor([0.0]).to(device)`: Punto de referencia para los logits.
        *   `pred = torch.gt(output, zero_tensor)`: `output` son los logits. `pred` será `True` si `output > 0` (predice clase 1, "not_bo"), y `False` si `output <= 0` (predice clase 0, "bo").
        *   `y` es un tensor de etiquetas (0.0 para "bo", 1.0 para "not_bo").
        *   `pred_labels = pred.float()`: Convierte las predicciones booleanas (`True`/`False`) a `1.0`/`0.0`.
        *   `correct = pred_labels.eq(y.view_as(pred_labels)).sum().item()`: Compara las etiquetas predichas (1.0/0.0) con las verdaderas (1.0/0.0).
        *   `return correct / y.size(0)`: Devuelve la precisión para el lote actual. La acumulación y promedio sobre la época se hará fuera.
    *   **Nota:** La implementación original de `get_batch_accuracy` en el cuaderno divide por `train_N` o `valid_N` (tamaño total del dataset) dentro de la función, lo que significa que la precisión retornada es una fracción de la precisión total de la época. Si se suma directamente como `accuracy += get_batch_accuracy(...)`, al final de la época `accuracy` será la precisión total de la época.

*   **Celda de Markdown (Imprimir Gradientes):**
    *   Se añade una opción para imprimir gradientes y verificar que solo las nuevas capas aprenden.

*   **Celda de Código (Función `train`):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    def train(model, check_grad=False):
        epoch_loss = 0
        epoch_accuracy = 0

        model.train() # Pone el modelo en modo entrenamiento
        for x, y in train_loader:
            # x ya está en device desde MyDataset. y también.
            # random_trans espera un tensor (C,H,W) o lote (B,C,H,W)
            # Si MyDataset carga imágenes individuales, random_trans se aplica a cada una.
            # Si se aplica a un lote, asegurarse que random_trans lo maneje.
            # torchvision.transforms.v2 usualmente se aplica a tensores individuales.
            # Es más común aplicar transformaciones en __getitem__ de Dataset o
            # si se aplica al lote, asegurar que la transformación esté diseñada para lotes.
            # Aquí, random_trans se aplica a x (un lote).
            # Si x es (B, C, H, W), random_trans(x) debería funcionar si las transformaciones son compatibles con lotes
            # o si se itera internamente. Para transforms.v2, se aplican a cada imagen del lote.
            
            transformed_x = random_trans(x) # Aplicar aumento de datos
            output = model(transformed_x)   # Salida es (batch_size, 1)
            output = torch.squeeze(output)  # Reduce a (batch_size) para BCEWithLogitsLoss si N_CLASSES=1

            optimizer.zero_grad()
            batch_loss = loss_function(output, y) # y ya es float y está en device
            batch_loss.backward()
            optimizer.step()

            epoch_loss += batch_loss.item()
            # Usando la versión corregida de get_batch_accuracy que devuelve precisión del lote:
            batch_accuracy = get_batch_accuracy(output, y, x.size(0)) # x.size(0) es el tamaño del lote actual
            epoch_accuracy += batch_accuracy * x.size(0) # Acumular correctas para promediar después

        if check_grad:
            print('Last Gradient (de la última capa entrenable):')
            # Imprimir gradientes de la última capa lineal añadida
            # my_model[1] es nn.Linear(1000, N_CLASSES)
            for param_name, param_val in my_model[1].named_parameters():
                 if param_val.grad is not None:
                    print(f"{param_name} grad norm: {param_val.grad.norm()}")


        avg_epoch_loss = epoch_loss / len(train_loader)
        avg_epoch_accuracy = epoch_accuracy / train_N # train_N es len(train_data)
        print(f'Train - Loss: {avg_epoch_loss:.4f} Accuracy: {avg_epoch_accuracy:.4f}')
    ```
    *   **Explicación (con mejoras sugeridas):**
        *   `model.train()`: Activa el modo entrenamiento.
        *   `transformed_x = random_trans(x)`: Aplica el aumento de datos al lote. `torchvision.transforms.v2` generalmente maneja lotes aplicando la transformación a cada imagen del lote.
        *   `output = torch.squeeze(model(transformed_x))`: `model(transformed_x)` da `(batch_size, 1)`. `squeeze` lo convierte a `(batch_size)` que `BCEWithLogitsLoss` espera si la etiqueta `y` es `(batch_size)`.
        *   `batch_loss = loss_function(output, y)`: `y` ya es float desde `MyDataset`.
        *   Se acumula la pérdida y la precisión. La precisión se promedia al final de la época.
        *   `check_grad`: Imprime información sobre los gradientes de la última capa si está activado.
    *   **Posibles Modificaciones:**
        *   La forma de aplicar `random_trans`. Si causa problemas con lotes, podría moverse a `MyDataset.__getitem__`.
        *   Detalles del cálculo de la precisión promedio.

*   **Celda de Markdown (Probar Gradientes):**
    *   Sugiere descomentar una línea para ver los gradientes.

*   **Celda de Código (Llamada de Prueba a `train` con `check_grad`):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    #train(my_model, check_grad=True) # Descomentar para probar
    ```

*   **Celda de Markdown (Función `validate`):**
    *   La función de validación es similar, pero sin aumento de datos ni retropropagación.

*   **Celda de Código (Función `validate`):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    def validate(model):
        epoch_loss = 0
        epoch_accuracy = 0

        model.eval() # Pone el modelo en modo evaluación
        with torch.no_grad(): # Desactiva el cálculo de gradientes
            for x, y in valid_loader:
                # x, y ya están en device
                output = model(x)
                output = torch.squeeze(output) # Reduce a (batch_size)

                epoch_loss += loss_function(output, y).item() # y ya es float
                # Usando la versión corregida de get_batch_accuracy:
                batch_accuracy = get_batch_accuracy(output, y, x.size(0))
                epoch_accuracy += batch_accuracy * x.size(0)

        avg_epoch_loss = epoch_loss / len(valid_loader)
        avg_epoch_accuracy = epoch_accuracy / valid_N # valid_N es len(valid_data)
        print(f'Valid - Loss: {avg_epoch_loss:.4f} Accuracy: {avg_epoch_accuracy:.4f}')
    ```
    *   **Explicación (con mejoras sugeridas):**
        *   `model.eval()`: Activa el modo evaluación.
        *   `with torch.no_grad()`: Optimización importante.
        *   No se aplica `random_trans`.
        *   Se acumula y promedia la pérdida y precisión.

*   **Celda de Markdown (Entrenamiento Inicial):**
    *   Pregunta si el modelo puede aprender a reconocer a Bo.

*   **Celda de Código (Bucle de Entrenamiento Inicial):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    epochs = 10

    for epoch in range(epochs):
        print('Epoch: {}'.format(epoch))
        train(my_model, check_grad=False) # Usar la función train definida localmente
        validate(my_model)                # Usar la función validate definida localmente
    ```
    *   **Explicación:** Entrena el modelo (solo las capas añadidas) durante 10 épocas.
    *   **Posibles Modificaciones:** Ajustar el número de `epochs`.

*   **Celda de Markdown (Discusión de Resultados Iniciales):**
    *   Se espera una precisión alta tanto en entrenamiento como en validación.
    *   La fluctuación en la validación es normal y se abordará con el ajuste fino.

## 5. Ajuste Fino del Modelo (Fine-Tuning)

Se descongelan las capas base y se reentrena todo el modelo con una tasa de aprendizaje muy baja.

*   **Celda de Markdown (Explicación de Fine-Tuning):**
    *   Después de entrenar las nuevas capas, se pueden descongelar las capas preentrenadas.
    *   Se entrena todo el modelo con una tasa de aprendizaje muy pequeña.
    *   Esto permite que las capas base se ajusten ligeramente a los nuevos datos sin destruir su conocimiento previo.
    *   Es importante hacerlo *después* de que las capas añadidas hayan convergido.

*   **Celda de Código (Descongelar y Nuevo Optimizador):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    # Unfreeze the base model
    vgg_model.requires_grad_(True) # Ahora los parámetros de vgg_model también son entrenables
    # Crear un nuevo optimizador que incluya todos los parámetros de my_model (incluidos los de vgg_model)
    # con una tasa de aprendizaje muy baja.
    optimizer = Adam(my_model.parameters(), lr=0.000001) # lr muy pequeña para fine-tuning
    ```
    *   **Explicación:**
        *   `vgg_model.requires_grad_(True)`: Hace que todos los parámetros de VGG16 sean entrenables.
        *   Se crea un **nuevo** optimizador `Adam` que ahora considerará todos los parámetros de `my_model` (incluidos los de `vgg_model`). La tasa de aprendizaje (`lr`) se establece muy baja (ej. `1e-6`).
    *   **Posibles Modificaciones:**
        *   La tasa de aprendizaje (`lr`) es crítica aquí; `1e-5` o `1e-6` son comunes.
        *   Podrías optar por descongelar solo algunas de las últimas capas de `vgg_model` en lugar de todas.

*   **Celda de Código (Bucle de Fine-Tuning):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    epochs = 2 # Pocas épocas para fine-tuning

    for epoch in range(epochs):
        print('Epoch: {}'.format(epoch))
        train(my_model, check_grad=False) # El mismo train, pero ahora el optimizador y requires_grad son diferentes
        validate(my_model)
    ```
    *   **Explicación:** Se entrena durante unas pocas épocas. VGG16 es grande y podría sobreajustar si se entrena demasiado tiempo en este dataset pequeño, incluso con `lr` baja.
    *   **Posibles Modificaciones:** Ajustar el número de `epochs` para el fine-tuning.

## 6. Examinando las Predicciones

Se crean funciones para visualizar y hacer predicciones con el modelo ajustado.

*   **Celda de Código (Funciones `show_image` y `make_prediction`):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    import matplotlib.pyplot as plt
    import matplotlib.image as mpimg

    def show_image(image_path): # Ya definida antes, pero se repite aquí
        image = mpimg.imread(image_path)
        plt.imshow(image)

    def make_prediction(file_path):
        show_image(file_path) # Muestra la imagen
        image_pil = Image.open(file_path) # Abre con PIL
        
        # Preprocesamiento:
        # 1. Aplicar pre_trans (de VGG weights)
        # 2. Mover a device
        # 3. Añadir dimensión de lote
        image_tensor = pre_trans(image_pil).to(device)
        image_batch = image_tensor.unsqueeze(0)
        
        my_model.eval() # Modo evaluación
        with torch.no_grad():
            output = my_model(image_batch) # Salida es (1, 1)
        
        prediction = output.item() # Obtiene el valor del logit como float
        return prediction
    ```
    *   **Explicación:**
        *   `make_prediction`:
            *   Carga y muestra la imagen.
            *   La preprocesa usando `pre_trans` (de VGG), la mueve al `device` y añade la dimensión de lote.
            *   Pasa la imagen por `my_model` en modo `eval`.
            *   Devuelve el logit de salida (un valor float).
    *   **Posibles Modificaciones:** Si el preprocesamiento cambia, esta función debe actualizarse.

*   **Celdas de Código (Probar `make_prediction`):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    make_prediction('data/presidential_doggy_door/valid/bo/bo_20.jpg')
    ```
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    make_prediction('data/presidential_doggy_door/valid/not_bo/121.jpg')
    ```
    *   **Explicación:** Muestra los logits de salida. Se observa que un número negativo parece indicar "Bo" y uno positivo "no Bo". (Esto depende de cómo se asignaron las etiquetas 0 y 1 en `DATA_LABELS` y la interpretación de `BCEWithLogitsLoss`). Si "bo" es clase 0 y "not_bo" es clase 1, un logit negativo significa que el modelo está más seguro de la clase 0 ("bo").

## 7. Ejercicio: Puerta de Bo

Implementar la lógica de la puerta basada en la predicción.

*   **Celda de Código (Función `presidential_doggy_door` - con FIXME):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    def presidential_doggy_door(image_path):
        pred = make_prediction(image_path) # Obtiene el logit
        if FIXME: # Condición basada en el valor de 'pred'
            print("It's Bo! Let him in!")
        else:
            print("That's not Bo! Stay out!")
    ```
    *   **Explicación:** El `FIXME` debe ser una condición que evalúe `pred`. Si `pred < 0` (o un umbral cercano a cero) indica "Bo".

*   **Celda de Código (Solución):**
    ```python
    # filepath: d:\UNJBG\NOVEMO SEMESTRE\SISTEMAS EXPERTOS\lab-sistemas-expertos\moedlos\05b_presidential_doggy_door.ipynb
    # SOLUTION
    def presidential_doggy_door(image_path):
        pred = make_prediction(image_path)
        if pred < 0: # Si el logit es negativo, es más probable que sea la clase 0 ("bo")
            print("It's Bo! Let him in!")
        else:
            print("That's not Bo! Stay out!")
    ```

*   **Celdas de Código (Probar `presidential_doggy_door`):**
    *   Se prueba la función con imágenes de Bo y no Bo.

## 8. Resumen y Siguientes Pasos

*   **Celda de Markdown (Resumen):**
    *   Se construyó un modelo preciso con un dataset pequeño usando aprendizaje por transferencia.
    *   Menciona NVIDIA TAO Toolkit como recurso.

*   **Celda de Código (Limpiar Memoria):**
    *   Reinicia el kernel para liberar memoria GPU.

Este desglose detallado debería ayudarte a comprender cada componente del cuaderno y a identificar dónde podrías realizar modificaciones para experimentar o adaptar el código.
