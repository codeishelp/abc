{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBNeKAyF3Y-h"
      },
      "source": [
        "# 4.a Aumento de Datos y Despliegue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTHY1Otu3Y-h"
      },
      "source": [
        "Hasta ahora, hemos seleccionado una arquitectura de modelo que mejora enormemente el rendimiento del modelo, ya que está diseñada para reconocer características importantes en las imágenes. La precisión de la validación sigue estando por detrás de la precisión del entrenamiento, lo que es un signo de sobreajuste: el modelo se confunde con cosas que no ha visto antes cuando se prueba con el conjunto de datos de validación.\n",
        "\n",
        "Para enseñar a nuestro modelo a ser más robusto ante nuevos datos, vamos a aumentar mediante programación el tamaño y la varianza de nuestro conjunto de datos. Esto se conoce como [*aumento de datos*](https://link.springer.com/article/10.1186/s40537-019-0197-0), una técnica útil para muchas aplicaciones de aprendizaje profundo.\n",
        "\n",
        "El aumento del tamaño proporciona al modelo más imágenes de las que aprender durante el entrenamiento. El aumento de la varianza ayuda al modelo a ignorar las características sin importancia y a seleccionar solo las características que son verdaderamente importantes en la clasificación, lo que le permite generalizar mejor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k01AskqI3Y-h"
      },
      "source": [
        "## 4a.1 Objetivos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCFOyxKS3Y-h"
      },
      "source": [
        "* Aumentar el conjunto de datos ASL\n",
        "* Utilizar los datos aumentados para entrenar un modelo mejorado.\n",
        "* Guarda el modelo bien entrenado en disco para utilizarlo en el despliegue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocl26UO63Y-i"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms.v2 as transforms\n",
        "import torchvision.transforms.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# import utils\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-FCWlRg3Y-h"
      },
      "source": [
        "## 4a.2 Preparación de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjSagpmG3Y-i"
      },
      "source": [
        "Como estamos en un cuaderno nuevo, cargaremos y procesaremos nuestros datos de nuevo. Para ello, ejecuta la siguiente celda:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y p7zip-full\n",
        "!wget https://github.com/ichaparroc/IA-EPIS/raw/refs/heads/main/ASL.7z -O ASL.7Z\n",
        "!7z x ASL.7Z"
      ],
      "metadata": {
        "id": "RWlhBfKZIqzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import utils"
      ],
      "metadata": {
        "id": "OHU_HjL6K5Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYhhD7yo2WEI"
      },
      "outputs": [],
      "source": [
        "IMG_HEIGHT = 28\n",
        "IMG_WIDTH = 28\n",
        "IMG_CHS = 1\n",
        "N_CLASSES = 24\n",
        "\n",
        "train_df = pd.read_csv(\"sign_mnist_train.csv\")\n",
        "valid_df = pd.read_csv(\"sign_mnist_valid.csv\")\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, base_df):\n",
        "        x_df = base_df.copy()\n",
        "        y_df = x_df.pop('label')\n",
        "        x_df = x_df.values / 255  # Normalize values from 0 to 1\n",
        "        x_df = x_df.reshape(-1, IMG_CHS, IMG_WIDTH, IMG_HEIGHT)\n",
        "        self.xs = torch.tensor(x_df).float().to(device)\n",
        "        self.ys = torch.tensor(y_df).to(device)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.xs[idx]\n",
        "        y = self.ys[idx]\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.xs)\n",
        "\n",
        "n = 32\n",
        "train_data = MyDataset(train_df)\n",
        "train_loader = DataLoader(train_data, batch_size=n, shuffle=True)\n",
        "train_N = len(train_loader.dataset)\n",
        "\n",
        "valid_data = MyDataset(valid_df)\n",
        "valid_loader = DataLoader(valid_data, batch_size=n)\n",
        "valid_N = len(valid_loader.dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwsfoZkE3Y-i"
      },
      "source": [
        "## 4a.3 Creación de modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze7Tv-Aj3Y-i"
      },
      "source": [
        "También tendremos que volver a crear nuestro modelo. Como aprendimos en la última lección, las redes neuronales convolucionales utilizan una secuencia repetida de capas. Aprovechemos este patrón para crear nuestro propio [módulo personalizado](https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html). Podemos entonces utilizar este módulo como una capa en nuestro modelo [Secuencial](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html).\n",
        "\n",
        "Para ello, extenderemos la clase [Módulo](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). Luego definiremos dos métodos:\n",
        "* `__init__`: define cualquier propiedad que queramos que tenga nuestro módulo, incluyendo las capas de nuestra red neuronal. Efectivamente estaremos usando un modelo dentro de otro modelo.\n",
        "* `forward`: define cómo queremos que el módulo procese los datos entrantes de la capa anterior a la que está conectado. Como estamos usando un modelo `Secuencial`, podemos pasarle los datos de entrada como si estuviéramos haciendo una predicción."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_o8Y7C91Bfl8"
      },
      "outputs": [],
      "source": [
        "class MyConvBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, dropout_p):\n",
        "        kernel_size = 3\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, kernel_size, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_p),\n",
        "            nn.MaxPool2d(2, stride=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tUW37SuICPW"
      },
      "source": [
        "Ahora que hemos definido nuestro módulo personalizado, veámoslo en acción. El modelo de abajo es archecturialmente el mismo que en la lección anterior. ¿Puedes ver la conexión?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0A_7iJvB8Kc"
      },
      "outputs": [],
      "source": [
        "flattened_img_size = 75 * 3 * 3\n",
        "\n",
        "# Input 1 x 28 x 28\n",
        "base_model = nn.Sequential(\n",
        "    MyConvBlock(IMG_CHS, 25, 0), # 25 x 14 x 14\n",
        "    MyConvBlock(25, 50, 0.2), # 50 x 7 x 7\n",
        "    MyConvBlock(50, 75, 0),  # 75 x 3 x 3\n",
        "    # Flatten to Dense Layers\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(flattened_img_size, 512),\n",
        "    nn.Dropout(.3),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, N_CLASSES)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7-rMWX7ICPX"
      },
      "source": [
        "Cuando imprimamos el modelo, no sólo mostrará ahora el uso de nuestro módulo personalizado, sino que también mostrará las capas dentro de nuestro módulo personalizado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4THc2t0HhNcv"
      },
      "outputs": [],
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = Adam(base_model.parameters())\n",
        "\n",
        "model = torch.compile(base_model.to(device))\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAeBoCvcICPZ"
      },
      "source": [
        "Los módulos personalizados son flexibles, y podemos definir cualquier otro método o propiedad que deseemos. Esto los hace potentes cuando los científicos de datos intentan resolver problemas complejos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjBNCzfc3Y-j"
      },
      "source": [
        "## 4a.4 Aumento de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8HdHKtM3Y-j"
      },
      "source": [
        "Antes de definir nuestro bucle de entrenamiento, es hora de configurar nuestro aumento de datos.\n",
        "\n",
        "Hemos visto [TorchVision](https://pytorch.org/vision/stable/index.html)'s [Transforms](https://pytorch.org/vision/0.9/transforms.html) antes, pero en esta lección, exploraremos más a fondo sus herramientas de aumento de datos. En primer lugar, vamos a obtener una imagen de muestra para probar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LT7NvrXhYwB"
      },
      "outputs": [],
      "source": [
        "row_0 = train_df.head(1)\n",
        "y_0 = row_0.pop('label')\n",
        "x_0 = row_0.values / 255\n",
        "x_0 = x_0.reshape(IMG_CHS, IMG_WIDTH, IMG_HEIGHT)\n",
        "x_0 = torch.tensor(x_0)\n",
        "x_0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKFRYIpvkUEF"
      },
      "outputs": [],
      "source": [
        "image = F.to_pil_image(x_0)\n",
        "plt.imshow(image, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7T-BvUeICPb"
      },
      "source": [
        "### 4a.4.1 [RandomResizeCrop](https://pytorch.org/vision/0.9/transforms.html#torchvision.transforms.RandomResizedCrop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UZxcliQICPc"
      },
      "source": [
        "Esta transformación cambiará aleatoriamente el tamaño de la imagen de entrada basándose en `scale`, y luego la [recortará](https://en.wikipedia.org/wiki/Cropping_(image)) al tamaño que especifiquemos. En este caso, la recortaremos a las dimensiones de la imagen original. Para hacer esto, TorchVision necesita saber la [relación de aspecto](https://en.wikipedia.org/wiki/Aspect_ratio_(image)) de la imagen que está escalando. Como nuestra altura es la misma que nuestra anchura, nuestra `relación` de aspecto es 1:1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWINTqKypE5J"
      },
      "outputs": [],
      "source": [
        "trans = transforms.Compose([\n",
        "    transforms.RandomResizedCrop((IMG_WIDTH, IMG_HEIGHT), scale=(.7, 1), ratio=(1, 1)),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7RYYHaMICPd"
      },
      "source": [
        "Pruebe a ejecutar la celda siguiente varias veces. Debería ser diferente cada vez."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZugUNuJpPG2"
      },
      "outputs": [],
      "source": [
        "new_x_0 = trans(x_0)\n",
        "image = F.to_pil_image(new_x_0)\n",
        "plt.imshow(image, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VQJ1vwKp4nJ"
      },
      "outputs": [],
      "source": [
        "new_x_0.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvwlrdv2ICPe"
      },
      "source": [
        "### 4a.4.2 [RandomHorizontalFlip](https://pytorch.org/vision/0.9/transforms.html#torchvision.transforms.RandomHorizontalFlip)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yrmm_inJ3Y-j"
      },
      "source": [
        "También podemos voltear aleatoriamente nuestras imágenes [Horizontalmente](https://pytorch.org/vision/0.9/transforms.html#torchvision.transforms.RandomHorizontalFlip) o [Verticalmente](https://pytorch.org/vision/0.9/transforms.html#torchvision.transforms.RandomVerticalFlip). Sin embargo, para estas imágenes, sólo las voltearemos horizontalmente.\n",
        "\n",
        "Piensa un momento por qué querríamos voltear las imágenes horizontalmente, pero no verticalmente. Cuando tengas una idea, revela el texto de abajo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCLufCeF3Y-j"
      },
      "source": [
        "`# SOLUCIÓN` Dato curioso: el lenguaje de signos americano puede hacerse con la mano izquierda o derecha dominante. Sin embargo, es poco probable ver el lenguaje de signos del revés. Este tipo de razonamiento específico del dominio puede ayudar a tomar buenas decisiones para tus propias aplicaciones de aprendizaje profundo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xo4BT2xBICPf"
      },
      "outputs": [],
      "source": [
        "trans = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip()\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utBy5vRdICPf"
      },
      "source": [
        "Intenta ejecutar la celda de abajo unas cuantas veces. ¿Se voltea la imagen la mitad de las veces?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVbQzIqCICPg"
      },
      "outputs": [],
      "source": [
        "new_x_0 = trans(x_0)\n",
        "image = F.to_pil_image(new_x_0)\n",
        "plt.imshow(image, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUaXmV36ICPg"
      },
      "source": [
        "### 4a.4.3 [RandomRotation](https://pytorch.org/vision/0.9/transforms.html#torchvision.transforms.RandomRotation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yiQecumICPg"
      },
      "source": [
        "También podemos rotar aleatoriamente la imagen para añadir más variabilidad. Al igual que con otras técnicas de aumento, es fácil pasarse accidentalmente. Con ASL, si rotamos demasiado, nuestras «D» pueden parecer «G» y viceversa. Por eso, limitémoslo a 30 grados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKj8CjZ_ICPg"
      },
      "outputs": [],
      "source": [
        "trans = transforms.Compose([\n",
        "    transforms.RandomRotation(10)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bC5U5sVLICPh"
      },
      "source": [
        "Cuando ejecutamos el bloque de celdas de abajo, pueden aparecer algunos píxeles negros. Las esquinas o nuestra imagen desaparecen cuando giramos, y por casi cada píxel que perdemos, ganamos un píxel vacío."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhAi9rUfICPh"
      },
      "outputs": [],
      "source": [
        "new_x_0 = trans(x_0)\n",
        "image = F.to_pil_image(new_x_0)\n",
        "plt.imshow(image, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g-RXRUjICPh"
      },
      "source": [
        "### 4a.4.3 [ColorJitter](https://pytorch.org/vision/0.9/transforms.html#torchvision.transforms.ColorJitter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86tcBqIDICPo"
      },
      "source": [
        "La transformación `ColorJitter` tiene 4 argumentos:\n",
        "* [brillo](https://en.wikipedia.org/wiki/Brightness)\n",
        "* [contraste](https://en.wikipedia.org/wiki/Contrast_(vision))\n",
        "* [saturación](https://en.wikipedia.org/wiki/Colorfulness#Saturation)\n",
        "* [tono](https://en.wikipedia.org/wiki/Hue)\n",
        "\n",
        "\n",
        "Los 2 últimos se aplican a las imágenes en color, así que por ahora sólo utilizaremos los 2 primeros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkyC609TICPo"
      },
      "outputs": [],
      "source": [
        "brightness = .2  # Change to be from 0 to 1\n",
        "contrast = .5  # Change to be from 0 to 1\n",
        "\n",
        "trans = transforms.Compose([\n",
        "    transforms.ColorJitter(brightness=brightness, contrast=contrast)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7wR42fEICPp"
      },
      "source": [
        "Pruebe a ejecutar lo siguiente varias veces, pero también pruebe a cambiar el `brillo` o el `contraste` a `1` en la celda anterior. ¿Obtiene algún resultado interesante?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcGF_K5HICPp"
      },
      "outputs": [],
      "source": [
        "new_x_0 = trans(x_0)\n",
        "image = F.to_pil_image(new_x_0)\n",
        "plt.imshow(image, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aFEm2HtICPq"
      },
      "source": [
        "### 4a.3.4 [Compose](https://pytorch.org/vision/0.9/transforms.html#torchvision.transforms.Compose)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm0QyMWOICPq"
      },
      "source": [
        "Es hora de unirlo todo. Podemos crear una secuencia de estas transformaciones aleatorias con `Compose`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkXjesFKFH_b"
      },
      "outputs": [],
      "source": [
        "random_transforms = transforms.Compose([\n",
        "    transforms.RandomRotation(5),\n",
        "    transforms.RandomResizedCrop((IMG_WIDTH, IMG_HEIGHT), scale=(.9, 1), ratio=(1, 1)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=.2, contrast=.5)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd-Ibca5ICPr"
      },
      "source": [
        "Hagamos la prueba. Con todas las combinaciones diferentes, ¿cuántas variaciones hay de esta imagen? ¿Infinitas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewG_7NAgqEnf"
      },
      "outputs": [],
      "source": [
        "new_x_0 = random_transforms(x_0)\n",
        "image = F.to_pil_image(new_x_0)\n",
        "plt.imshow(image, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zU7pCubICPr"
      },
      "source": [
        "### 4a.4 Entrenamiento con Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY3Q2R6BICPs"
      },
      "source": [
        "Nuestro entrenamiento es en su mayor parte el mismo, pero hay una línea de cambio. Antes de pasar nuestras imágenes a nuestro modelo, aplicaremos nuestras `random_transforms`. Por conveniencia, hemos movido `get_batch_accuracy` a un archivo `utils`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcgAmvx7rI13"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "\n",
        "    model.train()\n",
        "    for x, y in train_loader:\n",
        "        output = model(random_transforms(x))  # Updated\n",
        "        optimizer.zero_grad()\n",
        "        batch_loss = loss_function(output, y)\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss += batch_loss.item()\n",
        "        accuracy += utils.get_batch_accuracy(output, y, train_N)\n",
        "    print('Train - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y2NNZrFICPt"
      },
      "source": [
        "En el otro lado, la validación sigue siendo la misma. No hay transformaciones aleatorias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXc6lnRAR4qZ"
      },
      "outputs": [],
      "source": [
        "def validate():\n",
        "    loss = 0\n",
        "    accuracy = 0\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in valid_loader:\n",
        "            output = model(x)\n",
        "\n",
        "            loss += loss_function(output, y).item()\n",
        "            accuracy += utils.get_batch_accuracy(output, y, valid_N)\n",
        "    print('Valid - Loss: {:.4f} Accuracy: {:.4f}'.format(loss, accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkrXEyTzICPu"
      },
      "source": [
        "Pongamos a prueba el aumento de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isjOJIVArTLR"
      },
      "outputs": [],
      "source": [
        "import torch._dynamo\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "\n",
        "epochs = 20\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    train()\n",
        "    validate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0WoN84J3Y-l"
      },
      "source": [
        "## Discusión de resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EPTunxK3Y-l"
      },
      "source": [
        "Observará que la precisión de la validación es mayor y más coherente. Esto significa que nuestro modelo ya no se sobreajusta como antes; generaliza mejor, haciendo mejores predicciones con nuevos datos.\n",
        "\n",
        "La precisión del entrenamiento puede ser menor, y no pasa nada. En comparación con antes, el modelo está expuesto a una variedad mucho mayor de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npYY9cvA3Y-l"
      },
      "source": [
        "## Guardar el modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW_TgWkN3Y-l"
      },
      "source": [
        "Ahora que tenemos un modelo bien entrenado, querremos desplegarlo para realizar inferencias sobre nuevas imágenes.\n",
        "\n",
        "Es común, una vez que tenemos un modelo entrenado con el que estamos contentos, guardarlo en el disco. PyTorch tiene [múltiples maneras](https://pytorch.org/tutorials/beginner/saving_loading_models.html) para hacer esto, pero por ahora, vamos a utilizar `torch.save`. También necesitaremos guardar el código para nuestro módulo personalizado `MyConvBlock`, lo que hicimos en [utils.py](./utils.py). En el siguiente cuaderno, cargaremos el modelo y lo usaremos para leer nuevas imágenes del lenguaje de signos.\n",
        "\n",
        "PyTorch no puede guardar un modelo compilado ([ver este post](https://discuss.pytorch.org/t/how-to-save-load-a-model-with-torch-compile/179739)), así que en su lugar haremos lo siguiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snAS8LalsMv4"
      },
      "outputs": [],
      "source": [
        "torch.save(base_model, 'model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descarga el archivo model.pth, lo usarás para el laboratorio 4.b"
      ],
      "metadata": {
        "id": "uyNtjp0ZPaed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preguntas\n",
        "\n",
        "1. ¿Qué es el aumento de datos y por qué es importante en el aprendizaje profundo?\n",
        "\n",
        "2. Describe el papel de las capas convolucionales en una red neuronal.\n",
        "\n",
        "3. ¿Cuál es la diferencia entre la precisión de entrenamiento y la precisión de validación en un modelo de aprendizaje profundo?\n",
        "\n",
        "4. ¿Cómo afectan las transformaciones aleatorias como RandomHorizontalFlip y RandomRotation a la robustez del modelo?\n",
        "\n",
        "5. Da un ejemplo de cuándo una transformación podría no ser adecuada para ciertos tipos de datos.\n"
      ],
      "metadata": {
        "id": "5rnsG5x3OQR0"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}